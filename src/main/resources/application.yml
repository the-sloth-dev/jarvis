vaadin:
  # launches the browser when the application starts.
  launch-browser: false

logging:
  # control application logging.
  file:
    name: /tmp/jarvis.log
  level:
    dev:
      thesloth: DEBUG

spring:
  application:
    name: jarvis
  ai:
    openai:
      # The API Key
      api-key: ${CHAT_GPT_API_KEY}
      # Optionally, you can specify which organization to use for an API request.
      organization-id: ${CHAT_GPT_ORG_ID}
      # Optionally, you can specify which project to use for an API request.
      project-id: ${CHAT_GPT_PROJECT_ID}

      chat:
        options:
          # The name of the model to use.
          # Supported models: https://platform.openai.com/docs/pricing
          model: ${CHAT_MODEL:gpt-4o-mini}
          # The sampling temperature to use that controls the apparent creativity
          # of generated completions. Higher values will make output more random
          # while lower values will make results more focused and deterministic.
          # It is not recommended to modify temperature and top_p for the same
          # completions request as the interaction of these two settings is difficult to predict.
          temperature: 0.2
          # An alternative to sampling with temperature, called nucleus sampling,
          # where the model considers the results of the tokens with top_p probability mass.
          # So 0.1 means only the tokens comprising the top 10% probability mass are considered.
          # We generally recommend altering this or temperature but not both.
          topP: 0.3

  datasource:
    url: jdbc:postgresql://localhost:5433/postgres
    username: postgres
    password: postgres